{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I restarted the kernel after each cell!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What I am trying to do\n",
    "i.e. the following cell I want to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%0 : Float(128, 1, 64, 64)\n",
      "      %1 : Float(64, 1, 3, 3)\n",
      "      %2 : Float(64)\n",
      "      %3 : Float(64)\n",
      "      %4 : Float(64)\n",
      "      %5 : Float(64)\n",
      "      %6 : Float(64)\n",
      "      %7 : Long()\n",
      "      %8 : Float(64, 64, 4, 4)\n",
      "      %9 : Float(64)\n",
      "      %10 : Float(64)\n",
      "      %11 : Float(64)\n",
      "      %12 : Float(64)\n",
      "      %13 : Float(64)\n",
      "      %14 : Long()\n",
      "      %15 : Float(64, 64, 2, 2)\n",
      "      %16 : Float(64)\n",
      "      %17 : Float(64)\n",
      "      %18 : Float(64)\n",
      "      %19 : Float(64)\n",
      "      %20 : Float(64)\n",
      "      %21 : Long()\n",
      "      %22 : Float(64, 64, 3, 3)\n",
      "      %23 : Float(64)\n",
      "      %24 : Float(64)\n",
      "      %25 : Float(64)\n",
      "      %26 : Float(64)\n",
      "      %27 : Float(64)\n",
      "      %28 : Long()\n",
      "      %29 : Float(64, 64, 3, 3)\n",
      "      %30 : Float(64)\n",
      "      %31 : Float(64)\n",
      "      %32 : Float(64)\n",
      "      %33 : Float(64)\n",
      "      %34 : Float(64)\n",
      "      %35 : Long()\n",
      "      %36 : Float(10, 64)\n",
      "      %37 : Float(10)) {\n",
      "  %38 : Float(128, 64, 62, 62) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1]](%0, %1, %2), scope: Sequential/Conv2d[0]\n",
      "  %39 : Float(128, 64, 62, 62) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%38, %3, %4, %5, %6), scope: Sequential/BatchNorm2d[1]\n",
      "  %40 : Float(128, 64, 62, 62) = onnx::Relu(%39), scope: Sequential/ReLU[2]\n",
      "  %41 : Float(128, 64, 31, 31) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[4, 4], pads=[1, 1, 1, 1], strides=[2, 2]](%40, %8, %9), scope: Sequential/Conv2d[3]\n",
      "  %42 : Float(128, 64, 31, 31) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%41, %10, %11, %12, %13), scope: Sequential/BatchNorm2d[4]\n",
      "  %43 : Float(128, 64, 31, 31) = onnx::Relu(%42), scope: Sequential/ReLU[5]\n",
      "  %44 : Float(128, 64, 30, 30) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[1, 1]](%43, %15, %16), scope: Sequential/Conv2d[6]\n",
      "  %45 : Float(128, 64, 30, 30) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%44, %17, %18, %19, %20), scope: Sequential/ResidualBlock[7]/BatchNorm2d[norm_layer1]\n",
      "  %46 : Float(128, 64, 30, 30) = onnx::Relu(%45), scope: Sequential/ResidualBlock[7]/ReLU[relu_layer1]\n",
      "  %47 : Float(128, 64, 30, 30) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%46, %22, %23), scope: Sequential/ResidualBlock[7]/Conv2d[conv_layer1]\n",
      "  %48 : Float(128, 64, 30, 30) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%47, %24, %25, %26, %27), scope: Sequential/ResidualBlock[7]/BatchNorm2d[norm_layer2]\n",
      "  %49 : Float(128, 64, 30, 30) = onnx::Relu(%48), scope: Sequential/ResidualBlock[7]/ReLU[relu_layer2]\n",
      "  %50 : Float(128, 64, 30, 30) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%49, %29, %30), scope: Sequential/ResidualBlock[7]/Conv2d[conv_layer2]\n",
      "  %51 : Float(128, 64, 30, 30) = onnx::Add(%50, %44), scope: Sequential/ResidualBlock[7]\n",
      "  %52 : Float(128, 64, 30, 30) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%51, %31, %32, %33, %34), scope: Sequential/BatchNorm2d[8]\n",
      "  %53 : Float(128, 64, 30, 30) = onnx::Relu(%52), scope: Sequential/ReLU[9]\n",
      "  %54 : Float(128, 64, 1, 1) = onnx::GlobalAveragePool(%53), scope: Sequential/AdaptiveAvgPool2d[10]\n",
      "  %55 : Long() = onnx::Constant[value={0}](), scope: Sequential/Flatten[11]\n",
      "  %56 : Tensor = onnx::Shape(%54), scope: Sequential/Flatten[11]\n",
      "  %57 : Long() = onnx::Gather[axis=0](%56, %55), scope: Sequential/Flatten[11]\n",
      "  %58 : Long() = onnx::Constant[value={-1}](), scope: Sequential/Flatten[11]\n",
      "  %59 : Tensor = onnx::Unsqueeze[axes=[0]](%57)\n",
      "  %60 : Tensor = onnx::Unsqueeze[axes=[0]](%58)\n",
      "  %61 : Tensor = onnx::Concat[axis=0](%59, %60)\n",
      "  %62 : Float(128, 64) = onnx::Reshape(%54, %61), scope: Sequential/Flatten[11]\n",
      "  %63 : Float(128, 10) = onnx::Gemm[alpha=1, beta=1, transB=1](%62, %36, %37), scope: Sequential/Flatten[11]\n",
      "  return (%63);\n",
      "}\n",
      "\n",
      "Removed 5 superfluous nodes in graph\n",
      "Download complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/78 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Only Tensors of floating point dtype can require gradients",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4aea26becfc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m d5.test_training(executor, train_sampler, test_sampler, optimizer,\n\u001b[0;32m---> 54\u001b[0;31m                  EPOCHS, BATCH_SIZE, OUTPUT_NODE)\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.7.0/envs/neural_ode/lib/python3.7/site-packages/deep500/lv2/validation/training.py\u001b[0m in \u001b[0;36mtest_training\u001b[0;34m(executor, training_set, validation_set, optimizer, epochs, batch_size, output_node, metrics, events)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormal_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormal_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.0/envs/neural_ode/lib/python3.7/site-packages/deep500/lv2/runner.py\u001b[0m in \u001b[0;36mrun_loop\u001b[0;34m(self, epochs, events, collect_all_times)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;31m# Run test set prior to training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.0/envs/neural_ode/lib/python3.7/site-packages/deep500/lv2/runner.py\u001b[0m in \u001b[0;36m_test_accuracy\u001b[0;34m(self, stats, events)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_test_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_test_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_test_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.0/envs/neural_ode/lib/python3.7/site-packages/deep500/frameworks/pytorch/pytorch_graph_executor.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.0/envs/neural_ode/lib/python3.7/site-packages/deep500/frameworks/pytorch/pytorch_graph_executor.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPyTorchMetaVisitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.0/envs/neural_ode/lib/python3.7/site-packages/deep500/utils/onnx_interop/onnx_objects.py\u001b[0m in \u001b[0;36maccept\u001b[0;34m(self, visitor, network)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maccept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0mvisitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisitor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_input_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOnnxValueInfo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.0/envs/neural_ode/lib/python3.7/site-packages/deep500/utils/onnx_interop/onnx_objects.py\u001b[0m in \u001b[0;36maccept\u001b[0;34m(self, visitor, network)\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0mvisitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit_net_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meach_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0meach_initializer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mvisitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meach_initializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0mvisitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit_initializer_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0meach_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.0/envs/neural_ode/lib/python3.7/site-packages/deep500/frameworks/pytorch/pytorch_visitor.py\u001b[0m in \u001b[0;36mvisit_initializer\u001b[0;34m(self, each_initializer, network)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvisit_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meach_initializer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOnnxTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPyTorchNetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meach_initializer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meach_initializer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_param\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvisit_net_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOnnxValueInfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPyTorchNetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.0/envs/neural_ode/lib/python3.7/site-packages/deep500/frameworks/pytorch/pytorch_network.py\u001b[0m in \u001b[0;36mfeed_tensor\u001b[0;34m(self, name, new_value, device_option, is_param)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mnew_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0mnew_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Only Tensors of floating point dtype can require gradients"
     ]
    }
   ],
   "source": [
    "import deep500 as d5\n",
    "\n",
    "from deep500.frameworks import tensorflow as d5tf\n",
    "from deep500.frameworks import pytorch as d5torch\n",
    "from deep500.frameworks import reference as d5ref\n",
    "\n",
    "import deep500.networks as d5nt\n",
    "import deep500.datasets as d5ds\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "def model_to_onnx(model, batch_size, file_path, channels=1, height=64, width=64):\n",
    "    dummy_input = Variable(torch.randn(batch_size, channels, height, width))\n",
    "\n",
    "    torch.onnx.export(model, dummy_input, file_path, verbose=True)\n",
    "    return file_path\n",
    "\n",
    "\n",
    "\n",
    "# Get dataset size\n",
    "mnist_shape = d5ds.dataset_shape('mnist')\n",
    "classes, c, h, w = mnist_shape\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "import networks\n",
    "import torch.nn as nn\n",
    "my_model = nn.Sequential(*networks.get_downsampling_layers(), \n",
    "                         *networks.get_residual_blocks(1), \n",
    "                         *networks.get_final_layers()) #<-- build my own model-graph\n",
    "\n",
    "\n",
    "onnx_file = model_to_onnx(my_model, 128, \"test.onnx\")\n",
    "\n",
    "d5_model = d5.parser.load_and_parse_model(onnx_file) #<-- trying to turn it into D500\n",
    "\n",
    "INPUT_NODE = d5_model.get_input_nodes()[0].name\n",
    "OUTPUT_NODE = d5_model.get_output_nodes()[0].name\n",
    "\n",
    "train_set, test_set = d5ds.load_dataset('mnist', INPUT_NODE, 'labels')\n",
    "d5_model.add_operation(d5.ops.LabelCrossEntropy([OUTPUT_NODE, 'labels'], 'loss'))\n",
    "\n",
    "train_sampler = d5.ShuffleSampler(train_set, BATCH_SIZE)\n",
    "test_sampler = d5.ShuffleSampler(test_set, BATCH_SIZE)\n",
    "\n",
    "executor = d5torch.from_model(d5_model) #<<<--- here I use torch, \n",
    "    # which I have to do in order to use the adjoint method in backpropagation\n",
    "\n",
    "optimizer = d5ref.GradientDescent(executor, 'loss', 0.1)\n",
    "\n",
    "EPOCHS = 1\n",
    "d5.test_training(executor, train_sampler, test_sampler, optimizer,\n",
    "                 EPOCHS, BATCH_SIZE, OUTPUT_NODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ERROR: Using pytorch, with the example \"simple_cnn\"\n",
    "This gives a different error, but I think it should work\n",
    "\n",
    "It is the code from  \n",
    "from deep500/tutorials/custom_optimizer.ipynb   \n",
    "but using pytorch instead of tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clemens/.pyenv/versions/3.7.0/envs/neural_ode/lib/python3.7/site-packages/deep500/networks/pytorch_mnist.py:11: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  init.xavier_uniform(m.weight, gain=np.sqrt(2))\n",
      "/Users/clemens/.pyenv/versions/3.7.0/envs/neural_ode/lib/python3.7/site-packages/deep500/networks/pytorch_mnist.py:12: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(m.bias, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%0 : Float(128, 1, 28, 28)\n",
      "      %1 : Float(10, 1, 5, 5)\n",
      "      %2 : Float(10)\n",
      "      %3 : Float(20, 10, 5, 5)\n",
      "      %4 : Float(20)\n",
      "      %5 : Float(50, 320)\n",
      "      %6 : Float(50)\n",
      "      %7 : Float(10, 50)\n",
      "      %8 : Float(10)) {\n",
      "  %9 : Float(128, 10, 24, 24) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[0, 0, 0, 0], strides=[1, 1]](%0, %1, %2), scope: Net/Conv2d[conv1]\n",
      "  %10 : Float(128, 10, 12, 12) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%9), scope: Net\n",
      "  %11 : Float(128, 10, 12, 12) = onnx::Relu(%10), scope: Net\n",
      "  %12 : Float(128, 20, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[0, 0, 0, 0], strides=[1, 1]](%11, %3, %4), scope: Net/Conv2d[conv2]\n",
      "  %13 : Float(128, 20, 4, 4) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%12), scope: Net\n",
      "  %14 : Float(128, 20, 4, 4) = onnx::Relu(%13), scope: Net\n",
      "  %15 : Tensor = onnx::Constant[value=  -1  320 [ CPULongType{2} ]](), scope: Net\n",
      "  %16 : Float(128, 320) = onnx::Reshape(%14, %15), scope: Net\n",
      "  %17 : Float(128, 50) = onnx::Gemm[alpha=1, beta=1, transB=1](%16, %5, %6), scope: Net/Linear[fc1]\n",
      "  %18 : Float(128, 50) = onnx::Relu(%17), scope: Net\n",
      "  %19 : Float(128, 10) = onnx::Gemm[alpha=1, beta=1, transB=1](%18, %7, %8), scope: Net/Linear[fc2]\n",
      "  %20 : Float(128, 10) = onnx::Softmax[axis=1](%19), scope: Net\n",
      "  return (%20);\n",
      "}\n",
      "\n",
      "Download complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 78/78 [00:01<00:00, 61.85it/s, accuracy=2.21, test_loss=2.28]\n",
      "Training (epoch 1/1):   0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to fetch a None tensor grad_1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c9657320046b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m d5.test_training(executor, train_sampler, test_sampler, optimizer,\n\u001b[0;32m---> 37\u001b[0;31m                  EPOCHS, BATCH_SIZE, OUTPUT_NODE)\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.7.0/envs/neural_ode/lib/python3.7/site-packages/deep500/lv2/validation/training.py\u001b[0m in \u001b[0;36mtest_training\u001b[0;34m(executor, training_set, validation_set, optimizer, epochs, batch_size, output_node, metrics, events)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormal_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormal_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.0/envs/neural_ode/lib/python3.7/site-packages/deep500/lv2/runner.py\u001b[0m in \u001b[0;36mrun_loop\u001b[0;34m(self, epochs, events, collect_all_times)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_events\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.0/envs/neural_ode/lib/python3.7/site-packages/deep500/lv2/runner.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, stats, events, optimizer_events)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_training_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         output = self.optimizer.train(len(self.train_set), self.train_set, \n\u001b[0;32m---> 51\u001b[0;31m                                       optimizer_events)\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_training_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.0/envs/neural_ode/lib/python3.7/site-packages/deep500/lv2/optimizer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, iterations, sampler, events)\u001b[0m\n\u001b[1;32m     78\u001b[0m                     \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.0/envs/neural_ode/lib/python3.7/site-packages/deep500/lv2/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparam_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.0/envs/neural_ode/lib/python3.7/site-packages/deep500/frameworks/reference/optimizers.py\u001b[0m in \u001b[0;36mupdate_rule\u001b[0;34m(self, grad, old_param, param_name)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_param\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "import deep500 as d5\n",
    "\n",
    "from deep500.frameworks import tensorflow as d5tf\n",
    "from deep500.frameworks import pytorch as d5torch\n",
    "from deep500.frameworks import reference as d5ref\n",
    "\n",
    "import deep500.networks as d5nt\n",
    "import deep500.datasets as d5ds\n",
    "\n",
    "\n",
    "\n",
    "# Get dataset size\n",
    "mnist_shape = d5ds.dataset_shape('mnist')\n",
    "classes, c, h, w = mnist_shape\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "onnx_file = d5nt.export_network(\"simple_cnn\", BATCH_SIZE, classes=classes,\n",
    "                             channels=c, height=h, width=w)\n",
    "\n",
    "d5_model = d5.parser.load_and_parse_model(onnx_file)\n",
    "\n",
    "INPUT_NODE = d5_model.get_input_nodes()[0].name\n",
    "OUTPUT_NODE = d5_model.get_output_nodes()[0].name\n",
    "\n",
    "train_set, test_set = d5ds.load_dataset('mnist', INPUT_NODE, 'labels')\n",
    "d5_model.add_operation(d5.ops.LabelCrossEntropy([OUTPUT_NODE, 'labels'], 'loss'))\n",
    "\n",
    "train_sampler = d5.ShuffleSampler(train_set, BATCH_SIZE)\n",
    "test_sampler = d5.ShuffleSampler(test_set, BATCH_SIZE)\n",
    "\n",
    "executor = d5torch.from_model(d5_model) #<<<--- here I use pytorch\n",
    "\n",
    "optimizer = d5ref.GradientDescent(executor, 'loss', 0.1)\n",
    "\n",
    "EPOCHS = 1\n",
    "d5.test_training(executor, train_sampler, test_sampler, optimizer,\n",
    "                 EPOCHS, BATCH_SIZE, OUTPUT_NODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The same code but using tensorflow || this works\n",
    "from deep500/tutorials/custom_optimizer.ipynb\n",
    "\n",
    "and using the framework tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clemens/.pyenv/versions/3.7.0/envs/neural_ode/lib/python3.7/site-packages/deep500/networks/pytorch_mnist.py:11: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  init.xavier_uniform(m.weight, gain=np.sqrt(2))\n",
      "/Users/clemens/.pyenv/versions/3.7.0/envs/neural_ode/lib/python3.7/site-packages/deep500/networks/pytorch_mnist.py:12: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(m.bias, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%0 : Float(128, 1, 28, 28)\n",
      "      %1 : Float(10, 1, 5, 5)\n",
      "      %2 : Float(10)\n",
      "      %3 : Float(20, 10, 5, 5)\n",
      "      %4 : Float(20)\n",
      "      %5 : Float(50, 320)\n",
      "      %6 : Float(50)\n",
      "      %7 : Float(10, 50)\n",
      "      %8 : Float(10)) {\n",
      "  %9 : Float(128, 10, 24, 24) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[0, 0, 0, 0], strides=[1, 1]](%0, %1, %2), scope: Net/Conv2d[conv1]\n",
      "  %10 : Float(128, 10, 12, 12) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%9), scope: Net\n",
      "  %11 : Float(128, 10, 12, 12) = onnx::Relu(%10), scope: Net\n",
      "  %12 : Float(128, 20, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[0, 0, 0, 0], strides=[1, 1]](%11, %3, %4), scope: Net/Conv2d[conv2]\n",
      "  %13 : Float(128, 20, 4, 4) = onnx::MaxPool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2]](%12), scope: Net\n",
      "  %14 : Float(128, 20, 4, 4) = onnx::Relu(%13), scope: Net\n",
      "  %15 : Tensor = onnx::Constant[value=  -1  320 [ CPULongType{2} ]](), scope: Net\n",
      "  %16 : Float(128, 320) = onnx::Reshape(%14, %15), scope: Net\n",
      "  %17 : Float(128, 50) = onnx::Gemm[alpha=1, beta=1, transB=1](%16, %5, %6), scope: Net/Linear[fc1]\n",
      "  %18 : Float(128, 50) = onnx::Relu(%17), scope: Net\n",
      "  %19 : Float(128, 10) = onnx::Gemm[alpha=1, beta=1, transB=1](%18, %7, %8), scope: Net/Linear[fc2]\n",
      "  %20 : Float(128, 10) = onnx::Softmax[axis=1](%19), scope: Net\n",
      "  return (%20);\n",
      "}\n",
      "\n",
      "Download complete.\n",
      "WARNING:tensorflow:From /Users/clemens/.pyenv/versions/3.7.0/envs/neural_ode/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 78/78 [00:00<00:00, 97.62it/s, accuracy=8.83, test_loss=2.28]\n",
      "Training (epoch 1/1):   0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/clemens/.pyenv/versions/3.7.0/envs/neural_ode/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (epoch 1/1): 100%|██████████| 468/468 [00:12<00:00, 37.54it/s, batch_acc=96.1, loss_avg=0.443]\n",
      "Testing: 100%|██████████| 78/78 [00:00<00:00, 99.93it/s, accuracy=96.5, test_loss=0.107]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingAccuracy: 85.81396901709401\n",
      "TestAccuracy: 96.47435897435898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[85.81396901709401, 96.47435897435898]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import deep500 as d5\n",
    "\n",
    "from deep500.frameworks import tensorflow as d5tf\n",
    "from deep500.frameworks import pytorch as d5torch\n",
    "from deep500.frameworks import reference as d5ref\n",
    "\n",
    "import deep500.networks as d5nt\n",
    "import deep500.datasets as d5ds\n",
    "\n",
    "\n",
    "# Get dataset size\n",
    "mnist_shape = d5ds.dataset_shape('mnist')\n",
    "classes, c, h, w = mnist_shape\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# model = nn.Sequential(*get_downsamplint_layers(), *get_final_layers())\n",
    "\n",
    "# onnx_file = model_to_onnx(model, 128, \"test.onnx\")\n",
    "\n",
    "onnx_file = d5nt.export_network(\"simple_cnn\", BATCH_SIZE, classes=classes,\n",
    "                             channels=c, height=h, width=w)\n",
    "\n",
    "d5_model = d5.parser.load_and_parse_model(onnx_file)\n",
    "\n",
    "INPUT_NODE = d5_model.get_input_nodes()[0].name\n",
    "OUTPUT_NODE = d5_model.get_output_nodes()[0].name\n",
    "\n",
    "train_set, test_set = d5ds.load_dataset('mnist', INPUT_NODE, 'labels')\n",
    "d5_model.add_operation(d5.ops.LabelCrossEntropy([OUTPUT_NODE, 'labels'], 'loss'))\n",
    "\n",
    "train_sampler = d5.ShuffleSampler(train_set, BATCH_SIZE)\n",
    "test_sampler = d5.ShuffleSampler(test_set, BATCH_SIZE)\n",
    "\n",
    "executor = d5tf.from_model(d5_model) #<<<--- here I use tensorflow\n",
    "\n",
    "optimizer = d5ref.GradientDescent(executor, 'loss', 0.1)\n",
    "\n",
    "EPOCHS = 1\n",
    "d5.test_training(executor, train_sampler, test_sampler, optimizer,\n",
    "                 EPOCHS, BATCH_SIZE, OUTPUT_NODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
